#Exercise 5
set.seed(1234)
X1<- runif(10000, min=1, max=3)
X2<- rgamma(10000, shape=3, rate=0.5)
X3<- rbinom(10000, 1, 0.3)
e<- rnorm(10000, mean=2, sd=1)
Y<- 0.5 + 1.2*X1-0.9*X2 + 0.1*X3 + e
Y_hat=mean(Y)
ydum <- ifelse(Y>Y_hat, 1, 0)
#Exercise 6
r<- cor(Y, X1)
X<- cbind(X1, X2, X3)
b<- solve(t(X)%*%X)%*%t(X)%*%Y
b
diff<- b[1]-1.2
diff
paste("The difference from 1.2 is" diff)
diff<- b[1]-1.2
paste("The difference from 1.2 is" diff)
paste("The difference from 1.2 is", diff)
paste("The correlation coefficient between Y and X1 is", r)
paste("The regression coefficient between Y and X1 is", b[1])
paste("The difference from 1.2 is", diff)
#Exercise 5
set.seed(1234)
X1<- runif(10000, min=1, max=3)
X2<- rgamma(10000, shape=3, rate=0.5)
X3<- rbinom(10000, 1, 0.3)
e<- rnorm(10000, mean=2, sd=1)
Y<- 0.5 + 1.2*X1-0.9*X2 + 0.1*X3 + e
Y_hat=mean(Y)
ydum <- ifelse(Y>Y_hat, 1, 0)
#Exercise 6
r<- cor(Y, X1)
X<- cbind(1, X1, X2, X3)
b<- solve(t(X)%*%X)%*%t(X)%*%Y
diff<- b[2]-1.2
paste("The correlation coefficient between Y and X1 is", r)
paste("The regression coefficient between Y and X1 is", b[2])
paste("The difference from 1.2 is", diff)
cat("The regression result is Y=",b[1],"+",b[2],"X1+",b[3],"X2+",b[4],"X3+e")
cat("The coefficients are",b)
Varb<- var(e)*solve(t(X)%*%X)%*%t(X)%*%X%*%solve(t(X)%*%X)
Se <- sqrt(abs(Varb))
cat("The standard errors in this OLS are", Se[1,1],Se[2,2],Se[3,3],Se[4,4])
#Exercise 7
Probit<-glm(ydum~X1+X2+X3, family=binomial(link="probit"))
# flike and optim functions below are from professor's GitHub Class Note
flike = function(par,X1,X2,X3,ydum)
{
xbeta           = par[1] + par[2]*X1 + par[3]*X2 + par[4]*X3
pr              = pnorm(xbeta)
pr[pr>0.999999] = 0.999999
pr[pr<0.000001] = 0.000001
like           = ydum*log(pr) + (1-ydum)*log(1-pr)
return(-sum(like))
}
test_par = Probit$coefficients
flike(test_par,X1,X2,X3,ydum)
logLik(Probit)
out = mat.or.vec(100,4)
for (i0 in 1:100)
{
start    = runif(4,-10,10)
res  = optim(start,fn=flike,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),X1=X1,X2=X2,X3=X3,ydum=ydum,hessian=TRUE)
out[i0,] = res$par
}
start = runif(4)
res  = optim(start,fn=flike,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),X1=X1,X2=X2,X3=X3,ydum=ydum,hessian=TRUE)
fisher_info = solve(res$hessian)
prop_sigma  = sqrt(diag(fisher_info))
est = cbind(b ,summary(Probit)$coefficients[, 1],Probit$par,summary(Probit)$coefficients[, 2],prop_sigma)
colnames(est) = c("True parameter","R: GLM : est","R: own :se","R: GLM :se")
est
#Logit Model========================================
Logit<-glm(ydum~X1+X2+X3, family=binomial(link="logit"))
flike2 = function(par,X1,X2,X3,ydum)
{
xbeta           = par[1] + par[2]*X1 + par[3]*X2 + par[4]*X3
pr              = exp(xbeta)/(1+exp(xbeta))
pr[pr>0.999999] = 0.999999
pr[pr<0.000001] = 0.000001
like            = ydum*log(pr) + (1-ydum)*log(1-pr)
return(-sum(like))
}
test_par2 = Logit$coefficients
flike2(test_par2,X1,X2,X3,ydum)
logLik(Logit)
out = mat.or.vec(100,4)
for (i0 in 1:100)
{
start    = runif(4,-10,10)
res2     = optim(start,fn=flike2,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),X1=X1,X2=X2,X3=X3,ydum=ydum,hessian=TRUE)
out[i0,] = res2$par
}
start = runif(4)
res2  = optim(start,fn=flike,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),X1=X1,X2=X2,X3=X3,ydum=ydum,hessian=TRUE)
fisher_info2 = solve(res2$hessian)
prop_sigma2  = sqrt(diag(fisher_info2))
est2 = cbind(b ,summary(Logit)$coefficients[, 1],summary(Logit)$coefficients[, 2],Logit$par,prop_sigma)
colnames(est2) = c("True parameter","R: GLM : est","R: own :se","R: GLM :se")
est2
#linear probability model========================================
LPM<-lm(ydum~X1+X2+X3)
est3 = cbind(b ,summary(Probit)$coefficients[, 1],summary(Logit)$coefficients[, 1],summary(LPM)$coefficients[, 1])
colnames(est3) = c("True parameter","Probit","Logit","LPM")
est3
paste("Conclusion: the positive and negative signal of coefficients are same")
paste("The positive signals mean the variables hold positive influecne on ydum, and vice versa")
paste("For the intercept, X1 and X2, all the three models hold 0.001 significant level")
paste("But for X3, the Probit and Logit models hold 0.01 significant level. But for LPM, the X3 is not significant.")
#Exercise 8
summary(Logit)
summary(Probit)
probitmfx <-
function(formula, data, atmean = TRUE, robust = FALSE, clustervar1 = NULL,
clustervar2 = NULL, start = NULL, control = list()){
if(is.null(clustervar1) & !is.null(clustervar2)){
stop("use clustervar1 arguement before clustervar2 arguement")
}
if(!is.null(clustervar1)){
if(is.null(clustervar2)){
if(!(clustervar1 %in% names(data))){
stop("clustervar1 not in data.frame object")
}
data = data.frame(model.frame(formula, data, na.action=NULL),data[,clustervar1])
names(data)[dim(data)[2]] = clustervar1
data=na.omit(data)
}
if(!is.null(clustervar2)){
if(!(clustervar1 %in% names(data))){
stop("clustervar1 not in data.frame object")
}
if(!(clustervar2 %in% names(data))){
stop("clustervar2 not in data.frame object")
}
data = data.frame(model.frame(formula, data, na.action=NULL),
data[,c(clustervar1,clustervar2)])
names(data)[c(dim(data)[2]-1):dim(data)[2]] = c(clustervar1,clustervar2)
data=na.omit(data)
}
}
fit = glm(formula, data=data, family = binomial(link = "probit"), x=T,
start = start, control = control)
# terms needed
x1 = model.matrix(fit)
if (any(alias <- is.na(coef(fit)))) {
x1 <- x1[, !alias, drop = FALSE]
}
xm = as.matrix(colMeans(x1))
be = as.matrix(na.omit(coef(fit)))
k1 = length(na.omit(coef(fit)))
xb = t(xm) %*% be
fxb = ifelse(atmean==TRUE, dnorm(xb), mean(dnorm(x1 %*% be)))
# get variances
vcv = vcov(fit)
if(robust){
if(is.null(clustervar1)){
# white correction
vcv = vcovHC(fit, type = "HC0")
} else {
if(is.null(clustervar2)){
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=NULL)
} else {
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=clustervar2)
}
}
}
if(robust==FALSE & is.null(clustervar1)==FALSE){
if(is.null(clustervar2)){
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=NULL)
} else {
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=clustervar2)
}
}
mfx = data.frame(mfx=fxb*be, se=NA)
# get standard errors
if(atmean){
gr = as.numeric(fxb)*(diag(k1) - as.numeric(xb) *(be %*% t(xm)))
mfx$se = sqrt(diag(gr %*% vcv %*% t(gr)))
} else {
gr = apply(x1, 1, function(x){
as.numeric(as.numeric(dnorm(x %*% be))*(diag(k1) - as.numeric(x %*% be)*(be %*% t(x))))
})
gr = matrix(apply(gr,1,mean),nrow=k1)
mfx$se = sqrt(diag(gr %*% vcv %*% t(gr)))
}
mfx$discretechgvar = ifelse(rownames(mfx) %in% disch, 1, 0)
output = list(fit=fit, mfx=mfx)
return(output)
}
Datause<- as.data.frame(cbind(ydum, X1, X2, X3))
probitmfx(formula=ydum~X1+X2+X3, data=Datause)
disx1[,disch[i]] = max(x1[,disch[i]])
probitmfxest <-
function(formula, data, atmean = TRUE, robust = FALSE, clustervar1 = NULL,
clustervar2 = NULL, start = NULL, control = list()){
if(is.null(formula)){
stop("formula is missing")
}
if(!is.data.frame(data)){
stop("data arguement must contain data.frame object")
}
# cluster sort part
if(is.null(clustervar1) & !is.null(clustervar2)){
stop("use clustervar1 arguement before clustervar2 arguement")
}
if(!is.null(clustervar1)){
if(is.null(clustervar2)){
if(!(clustervar1 %in% names(data))){
stop("clustervar1 not in data.frame object")
}
data = data.frame(model.frame(formula, data, na.action=NULL),data[,clustervar1])
names(data)[dim(data)[2]] = clustervar1
data=na.omit(data)
}
if(!is.null(clustervar2)){
if(!(clustervar1 %in% names(data))){
stop("clustervar1 not in data.frame object")
}
if(!(clustervar2 %in% names(data))){
stop("clustervar2 not in data.frame object")
}
data = data.frame(model.frame(formula, data, na.action=NULL),
data[,c(clustervar1,clustervar2)])
names(data)[c(dim(data)[2]-1):dim(data)[2]] = c(clustervar1,clustervar2)
data=na.omit(data)
}
}
fit = glm(formula, data=data, family = binomial(link = "probit"), x=T,
start = start, control = control)
# terms needed
x1 = model.matrix(fit)
if (any(alias <- is.na(coef(fit)))) {
x1 <- x1[, !alias, drop = FALSE]
}
xm = as.matrix(colMeans(x1))
be = as.matrix(na.omit(coef(fit)))
k1 = length(na.omit(coef(fit)))
xb = t(xm) %*% be
fxb = ifelse(atmean==TRUE, dnorm(xb), mean(dnorm(x1 %*% be)))
# get variances
vcv = vcov(fit)
if(robust){
if(is.null(clustervar1)){
# white correction
vcv = vcovHC(fit, type = "HC0")
} else {
if(is.null(clustervar2)){
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=NULL)
} else {
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=clustervar2)
}
}
}
if(robust==FALSE & is.null(clustervar1)==FALSE){
if(is.null(clustervar2)){
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=NULL)
} else {
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=clustervar2)
}
}
mfx = data.frame(mfx=fxb*be, se=NA)
# get standard errors
if(atmean){
gr = as.numeric(fxb)*(diag(k1) - as.numeric(xb) *(be %*% t(xm)))
mfx$se = sqrt(diag(gr %*% vcv %*% t(gr)))
} else {
gr = apply(x1, 1, function(x){
as.numeric(as.numeric(dnorm(x %*% be))*(diag(k1) - as.numeric(x %*% be)*(be %*% t(x))))
})
gr = matrix(apply(gr,1,mean),nrow=k1)
mfx$se = sqrt(diag(gr %*% vcv %*% t(gr)))
}
# pick out constant and remove from mfx table
temp1 = apply(x1,2,function(x)length(table(x))==1)
const = names(temp1[temp1==TRUE])
mfx = mfx[row.names(mfx)!=const,]
# pick out discrete change variables
temp1 = apply(x1,2,function(x)length(table(x))==2)
disch = names(temp1[temp1==TRUE])
# calculte the disctrete change marginal effects and standard errors
if(length(disch)!=0){
for(i in 1:length(disch)){
if(atmean){
disx0 = disx1 = xm
disx1[disch[i],] = max(x1[,disch[i]])
disx0[disch[i],] = min(x1[,disch[i]])
mfx[disch[i],1] = pnorm(t(be) %*% disx1) - pnorm(t(be) %*% disx0)
# standard errors
gr = dnorm(t(be) %*% disx1) %*% t(disx1) - dnorm(t(be) %*% disx0) %*% t(disx0)
mfx[disch[i],2] = sqrt(gr %*% vcv %*% t(gr))
} else {
disx0 = disx1 = x1
disx1[,disch[i]] = max(x1[,disch[i]])
disx0[,disch[i]] = min(x1[,disch[i]])
mfx[disch[i],1] = mean(pnorm(disx1 %*% be) - pnorm(disx0 %*% be))
# standard errors
gr = as.numeric(dnorm(disx1 %*% be)) * disx1 - as.numeric(dnorm(disx0 %*% be)) * disx0
avegr = as.matrix(colMeans(gr))
mfx[disch[i],2] = sqrt(t(avegr) %*% vcv %*% avegr)
}
}
}
mfx$discretechgvar = ifelse(rownames(mfx) %in% disch, 1, 0)
output = list(fit=fit, mfx=mfx)
return(output)
}
probitmfx(formula=ydum~X1+X2+X3, data=Datause)
probitmfxest(formula=ydum~X1+X2+X3, data=Datause)
probitmfxest <-
function(formula, data, atmean = TRUE, robust = FALSE, clustervar1 = NULL,
clustervar2 = NULL, start = NULL, control = list()){
if(is.null(formula)){
stop("formula is missing")
}
if(!is.data.frame(data)){
stop("data arguement must contain data.frame object")
}
# cluster sort part
if(is.null(clustervar1) & !is.null(clustervar2)){
stop("use clustervar1 arguement before clustervar2 arguement")
}
if(!is.null(clustervar1)){
if(is.null(clustervar2)){
if(!(clustervar1 %in% names(data))){
stop("clustervar1 not in data.frame object")
}
data = data.frame(model.frame(formula, data, na.action=NULL),data[,clustervar1])
names(data)[dim(data)[2]] = clustervar1
data=na.omit(data)
}
if(!is.null(clustervar2)){
if(!(clustervar1 %in% names(data))){
stop("clustervar1 not in data.frame object")
}
if(!(clustervar2 %in% names(data))){
stop("clustervar2 not in data.frame object")
}
data = data.frame(model.frame(formula, data, na.action=NULL),
data[,c(clustervar1,clustervar2)])
names(data)[c(dim(data)[2]-1):dim(data)[2]] = c(clustervar1,clustervar2)
data=na.omit(data)
}
}
fit = glm(formula, data=data, family = binomial(link = "probit"), x=T,
start = start, control = control)
# terms needed
x1 = model.matrix(fit)
if (any(alias <- is.na(coef(fit)))) {
x1 <- x1[, !alias, drop = FALSE]
}
xm = as.matrix(colMeans(x1))
be = as.matrix(na.omit(coef(fit)))
k1 = length(na.omit(coef(fit)))
xb = t(xm) %*% be
fxb = ifelse(atmean==TRUE, dnorm(xb), mean(dnorm(x1 %*% be)))
# get variances
vcv = vcov(fit)
if(robust){
if(is.null(clustervar1)){
# white correction
vcv = vcovHC(fit, type = "HC0")
} else {
if(is.null(clustervar2)){
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=NULL)
} else {
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=clustervar2)
}
}
}
if(robust==FALSE & is.null(clustervar1)==FALSE){
if(is.null(clustervar2)){
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=NULL)
} else {
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=clustervar2)
}
}
mfx = data.frame(mfx=fxb*be, se=NA)
# get standard errors
if(atmean){
gr = as.numeric(fxb)*(diag(k1) - as.numeric(xb) *(be %*% t(xm)))
mfx$se = sqrt(diag(gr %*% vcv %*% t(gr)))
} else {
gr = apply(x1, 1, function(x){
as.numeric(as.numeric(dnorm(x %*% be))*(diag(k1) - as.numeric(x %*% be)*(be %*% t(x))))
})
gr = matrix(apply(gr,1,mean),nrow=k1)
mfx$se = sqrt(diag(gr %*% vcv %*% t(gr)))
}
output = list(fit=fit, mfx=mfx)
return(output)
}
probitmfxest(formula=ydum~X1+X2+X3, data=Datause)
logitmfxest <-
function(formula, data, atmean = TRUE, robust = FALSE, clustervar1 = NULL,
clustervar2 = NULL, start = NULL, control = list()){
if(is.null(formula)){
stop("formula is missing")
}
if(!is.data.frame(data)){
stop("data arguement must contain data.frame object")
}
# cluster sort part
if(is.null(clustervar1) & !is.null(clustervar2)){
stop("use clustervar1 arguement before clustervar2 arguement")
}
if(!is.null(clustervar1)){
if(is.null(clustervar2)){
if(!(clustervar1 %in% names(data))){
stop("clustervar1 not in data.frame object")
}
data = data.frame(model.frame(formula, data, na.action=NULL),data[,clustervar1])
names(data)[dim(data)[2]] = clustervar1
data=na.omit(data)
}
if(!is.null(clustervar2)){
if(!(clustervar1 %in% names(data))){
stop("clustervar1 not in data.frame object")
}
if(!(clustervar2 %in% names(data))){
stop("clustervar2 not in data.frame object")
}
data = data.frame(model.frame(formula, data, na.action=NULL),
data[,c(clustervar1,clustervar2)])
names(data)[c(dim(data)[2]-1):dim(data)[2]] = c(clustervar1,clustervar2)
data=na.omit(data)
}
}
fit = glm(formula, data=data, family = binomial(link = "logit"), x=T,
start = start, control = control)
# terms needed
x1 = model.matrix(fit)
if (any(alias <- is.na(coef(fit)))) {
x1 <- x1[, !alias, drop = FALSE]
}
xm = as.matrix(colMeans(x1))
be = as.matrix(na.omit(coef(fit)))
k1 = length(na.omit(coef(fit)))
xb = t(xm) %*% be
fxb = ifelse(atmean==TRUE, plogis(xb)*(1-plogis(xb)), mean(plogis(x1 %*% be)*(1-plogis(x1 %*% be))))
# get variances
vcv = vcov(fit)
if(robust){
if(is.null(clustervar1)){
# white correction
vcv = vcovHC(fit, type = "HC0")
} else {
if(is.null(clustervar2)){
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=NULL)
} else {
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=clustervar2)
}
}
}
if(robust==FALSE & is.null(clustervar1)==FALSE){
if(is.null(clustervar2)){
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=NULL)
} else {
vcv = clusterVCV(data=data, fm=fit, cluster1=clustervar1,cluster2=clustervar2)
}
}
mfx = data.frame(mfx=fxb*be, se=NA)
# get standard errors
if(atmean){
gr = (as.numeric(fxb))*(diag(k1) + as.numeric(1 - 2*plogis(xb))*(be %*% t(xm)))
mfx$se = sqrt(diag(gr %*% vcv %*% t(gr)))
} else {
gr = apply(x1, 1, function(x){
as.numeric(as.numeric(plogis(x %*% be)*(1-plogis(x %*% be)))*
(diag(k1) - (1 - 2*as.numeric(plogis(x %*% be)))*(be %*% t(x))))
})
gr = matrix(apply(gr,1,mean),nrow=k1)
mfx$se = sqrt(diag(gr %*% vcv %*% t(gr)))
}
output = list(fit=fit, mfx=mfx)
return(output)
}
logitmfxest(formula=ydum~X1+X2+X3, data=Datause)
paste("The answers of Exercise 8 are in the tables below")
PE<- probitmfxest(formula=ydum~X1+X2+X3, data=Datause)
ME<- logitmfxest(formula=ydum~X1+X2+X3, data=Datause)
cbing(PE, ME)
paste("The answers of Exercise 8 are in the tables below")
probitmfxest(formula=ydum~X1+X2+X3, data=Datause)
logitmfxest(formula=ydum~X1+X2+X3, data=Datause)
